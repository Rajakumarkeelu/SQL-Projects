# SQL Project: Transaction Data Analysis  

## Overview  
This project focuses on optimizing and analyzing a dataset of over 13 million rows. The goal is to transform and structure the data efficiently for better performance and ease of use in Power BI and Tableau.  

## Dataset  
- Source: Kaggle (Transaction Dataset)  
- Size: 13+ million records  
- Columns: ID, Date, Client ID, Card ID, Amount, Merchant Info, Errors, etc.  

## Key Steps  
- Imported raw transaction data into SQL Server  
- Cleaned and optimized data by creating lighter, more structured tables  
- Performed transformations to improve efficiency  
- Prepared data for use in Power BI and Tableau  

## SQL Techniques Used  
- DDL (Data Definition Language): Created and optimized tables  
- DML (Data Manipulation Language): Cleaned and transformed data  
- Indexing: Improved query performance  
- Joins & Aggregations: Prepared for analytics  

## Next Steps  
- Perform deeper fraud detection analysis  
- Create Power BI dashboards  
- Optimize queries further for performance tuning  

## Files  
- **Transaction_Data_Analysis.sql** – SQL scripts used in this project  

---

**Author:** [Rajakumar Keelu](https://github.com/Rajakumarkeelu)  
*"Data world… Brace yourself. The next genius is arriving!"*
